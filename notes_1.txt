Hadoop Ecosystem
- a platform or framework which solves big data problems
- suite which encompasses a no. of services (storing, analyzing and maintaining)

NameNode
- Master daemon that maintains and manages the DataNodes (slave nodes)
- it records the meta data of all files stored in cluster...eg- location of blocks stored, the size of the files, permissions etc...
- it records each and every change that takes place to the file system metadata.

It regularly receives a heartbeat and a block report from all the DataNodes in the cluster to ensure that the dataNodes are alive.

DataNode
- Slave daemon which runs on slave machines.
- actual data is stored on DataNodes.
- responsible for read and write req from clients

Resource Manager
- cluster level (one for each cluster) component and runs on master machine.
- manages resources and schedule applications running on top of YARN.

NodeManager
- node level component (one on each node) and runs on slave machine.
- keeps tarck of node health and log management.
- It continuously communicates with ResourceManages to remain up-to-date


MapReduce
- Core Component of processing in a hadoop Ecosystem as it provides the logic processing.
- a software framework which helps writing applications that process larget data sets using distributed and parallel algorithms.

Map() - performs action like filtering, grouping, sorting
Reduce() - aggregates and summarizes the result produced by map fuction.
Result generated by map() is a key:value pair which acts as the input for reduce()
